{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98676d9f",
   "metadata": {
    "id": "98676d9f"
   },
   "outputs": [],
   "source": [
    "# pip install datasets pillow pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73c91a8",
   "metadata": {
    "id": "c73c91a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saran\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## STEP 1: IMPORTS AND CONFIGURATION\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYxZpR9EMSjN",
   "metadata": {
    "id": "BYxZpR9EMSjN"
   },
   "source": [
    "### 25 Selected Classes with COCO Category IDs\n",
    "\n",
    "**Vehicles:** car(3), truck(8), bus(6), motorcycle(4), bicycle(2), airplane(5)  \n",
    "**Person:** person(1)  \n",
    "**Outdoor:** traffic light(10), stop sign(13), bench(15)  \n",
    "**Animals:** dog(18), cat(17), horse(19), bird(16), cow(21), elephant(22)  \n",
    "**Kitchen & Food:** bottle(44), cup(47), bowl(51), pizza(59), cake(61)  \n",
    "**Furniture:** chair(62), couch(63), bed(65), potted plant(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531afa7c",
   "metadata": {
    "id": "531afa7c"
   },
   "outputs": [],
   "source": [
    "# 25 Selected Classes (COCO category IDs)\n",
    "\n",
    "SELECTED_CLASSES = {\n",
    "    'person': 1,\n",
    "    'bicycle': 2,\n",
    "    'car': 3,\n",
    "    'motorcycle': 4,\n",
    "    'airplane': 5,\n",
    "    'bus': 6,\n",
    "    'truck': 8,\n",
    "    'traffic light': 10,\n",
    "    'stop sign': 13,\n",
    "    'bench': 15,\n",
    "    'bird': 16,\n",
    "    'cat': 17,\n",
    "    'dog': 18,\n",
    "    'horse': 19,\n",
    "    'cow': 21,\n",
    "    'elephant': 22,\n",
    "    'bottle': 44,\n",
    "    'cup': 47,\n",
    "    'bowl': 51,\n",
    "    'pizza': 59,\n",
    "    'cake': 61,\n",
    "    'chair': 62,\n",
    "    'couch': 63,\n",
    "    'bed': 65,\n",
    "    'potted plant': 64\n",
    "}\n",
    "\n",
    "IMAGES_PER_CLASS = 100\n",
    "BASE_DIR = \"smartvision_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91700ca9",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e0b058bf2f6a4c6597809c8144c276bd"
     ]
    },
    "id": "91700ca9",
    "outputId": "5c118f1f-c82e-41e6-bba9-18c920b36ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading COCO dataset in STREAMING mode (no download)...\n",
      "‚úÖ Dataset loaded in streaming mode!\n"
     ]
    }
   ],
   "source": [
    "## STEP 2: LOAD COCO DATASET FROM HUGGING FACE\n",
    "\n",
    "print(\"üì• Loading COCO dataset in STREAMING mode (no download)...\")\n",
    "dataset = load_dataset(\"detection-datasets/coco\", split=\"train\", streaming=True)\n",
    "print(\"‚úÖ Dataset loaded in streaming mode!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3056a4a",
   "metadata": {
    "id": "c3056a4a",
    "outputId": "9e873ef2-5c58-4b59-d2b7-1b1d4d39d48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Starting image collection from COCO dataset stream...\n",
      "üéØ Target: 100 images per class\n",
      "\n",
      "‚è≥ Processing images from stream...\n",
      "üí° Progress updates every 100 images collected\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 2010d019-4c01-496a-a737-380a3e888946)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000231F51AED50>: Failed to establish a new connection: [WinError 10065] A socket operation was attempted to an unreachable host'))\"), '(Request ID: ba9d6050-def4-4e72-a5a2-32fad4276c96)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000231F51AEFD0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 34482484-1204-4578-a336-24a40b5af9ca)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 5c269614-e077-408a-9a73-af83bebfa783)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d27c8077-7cd4-4a7e-b3c8-88c71e86e730)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000231F52BC2D0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 0334c988-f40a-47da-b589-66281ca6af90)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000231F52BC690>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 61de0146-46cd-4249-9674-7df8196e9240)')' thrown while requesting GET https://huggingface.co/datasets/detection-datasets/coco/resolve/cf0b22332314a937e9dc8a1957b21725430bb41d/data/train-00000-of-00040-67e35002d152155c.parquet\n",
      "Got disconnected from remote data host. Retrying in 5sec [1/20]\n"
     ]
    }
   ],
   "source": [
    "## STEP 3: COLLECT IMAGES FROM STREAM\n",
    "\n",
    "print(\"\\nüîç Starting image collection from COCO dataset stream...\")\n",
    "print(f\"üéØ Target: {IMAGES_PER_CLASS} images per class\")\n",
    "print()\n",
    "\n",
    "# Initialize storage for collected images\n",
    "class_images = {class_name: [] for class_name in SELECTED_CLASSES.keys()}\n",
    "class_counts = {class_name: 0 for class_name in SELECTED_CLASSES.keys()}\n",
    "\n",
    "# Progress tracking\n",
    "total_collected = 0\n",
    "images_processed = 0\n",
    "max_iterations = 50000  # Safety limit\n",
    "\n",
    "print(\"‚è≥ Processing images from stream...\")\n",
    "print(\"üí° Progress updates every 100 images collected\")\n",
    "print()\n",
    "\n",
    "# Iterate through streaming dataset\n",
    "for idx, item in enumerate(dataset):\n",
    "\n",
    "    images_processed += 1\n",
    "\n",
    "    # Progress update every 1000 images processed\n",
    "    if images_processed % 1000 == 0:\n",
    "        print(f\"üìä Processed {images_processed} images | Collected {total_collected}/{len(SELECTED_CLASSES) * IMAGES_PER_CLASS}\")\n",
    "\n",
    "    # Safety check\n",
    "    if images_processed >= max_iterations:\n",
    "        print(f\"‚ö†Ô∏è Reached safety limit of {max_iterations} iterations\")\n",
    "        break\n",
    "\n",
    "    # Check if we have enough images for ALL classes\n",
    "    if all(count >= IMAGES_PER_CLASS for count in class_counts.values()):\n",
    "        print(\"üéâ Successfully collected 100 images for ALL classes!\")\n",
    "        break\n",
    "\n",
    "    # Get annotations from current image\n",
    "    annotations = item['objects']\n",
    "    categories = annotations['category']\n",
    "\n",
    "    # Check if any of our target classes are in this image\n",
    "    for cat_id in categories:\n",
    "        for class_name, class_id in SELECTED_CLASSES.items():\n",
    "            if cat_id == class_id and class_counts[class_name] < IMAGES_PER_CLASS:\n",
    "\n",
    "                # Store the ACTUAL image data (not just index!)\n",
    "                class_images[class_name].append({\n",
    "                    'image': item['image'],           # PIL Image object\n",
    "                    'annotations': item['objects'],   # Annotations\n",
    "                    'idx': images_processed           # For naming\n",
    "                })\n",
    "\n",
    "                class_counts[class_name] += 1\n",
    "                total_collected += 1\n",
    "\n",
    "                # Progress update every 100 collected\n",
    "                if total_collected % 100 == 0:\n",
    "                    print(f\"‚úì Collected {total_collected}/{len(SELECTED_CLASSES) * IMAGES_PER_CLASS} images\")\n",
    "\n",
    "                break  # Only count once per class\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"üìä COLLECTION COMPLETE:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Images Processed: {images_processed}\")\n",
    "print(f\"Images Collected: {total_collected}\")\n",
    "print()\n",
    "for class_name, count in sorted(class_counts.items()):\n",
    "    status = \"‚úÖ\" if count >= IMAGES_PER_CLASS else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {class_name:20s}: {count:3d} images\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b344d",
   "metadata": {
    "id": "216b344d",
    "outputId": "3da8bbb1-7618-4d8d-bbf2-9e96a4d0dc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Creating project folder structure...\n",
      "\n",
      "‚úÖ Folder structure created successfully!\n",
      "\n",
      "üìÇ Structure:\n",
      "\n",
      "smartvision_dataset/\n",
      "‚îú‚îÄ‚îÄ classification/\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ person/\n",
      "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ car/\n",
      "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (25 class folders)\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
      "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (25 class folders)\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
      "‚îÇ       ‚îî‚îÄ‚îÄ ... (25 class folders)\n",
      "‚îÇ\n",
      "‚îî‚îÄ‚îÄ detection/\n",
      "    ‚îú‚îÄ‚îÄ images/\n",
      "    ‚îî‚îÄ‚îÄ labels/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## STEP 4: CREATE FOLDER STRUCTURE\n",
    "\n",
    "print(\"\\nüìÅ Creating project folder structure...\")\n",
    "print()\n",
    "\n",
    "# Create main directory\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# Create subdirectories for Classification task\n",
    "os.makedirs(f\"{BASE_DIR}/classification/train\", exist_ok=True)\n",
    "os.makedirs(f\"{BASE_DIR}/classification/val\", exist_ok=True)\n",
    "os.makedirs(f\"{BASE_DIR}/classification/test\", exist_ok=True)\n",
    "\n",
    "# Create subdirectories for Detection task\n",
    "os.makedirs(f\"{BASE_DIR}/detection/images\", exist_ok=True)\n",
    "os.makedirs(f\"{BASE_DIR}/detection/labels\", exist_ok=True)\n",
    "\n",
    "# Create class folders inside train/val/test\n",
    "for class_name in SELECTED_CLASSES.keys():\n",
    "    os.makedirs(f\"{BASE_DIR}/classification/train/{class_name}\", exist_ok=True)\n",
    "    os.makedirs(f\"{BASE_DIR}/classification/val/{class_name}\", exist_ok=True)\n",
    "    os.makedirs(f\"{BASE_DIR}/classification/test/{class_name}\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Folder structure created successfully!\")\n",
    "print()\n",
    "print(\"üìÇ Structure:\")\n",
    "print(f\"\"\"\n",
    "{BASE_DIR}/\n",
    "‚îú‚îÄ‚îÄ classification/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ person/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ car/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (25 class folders)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (25 class folders)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ ... (25 class folders)\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ detection/\n",
    "    ‚îú‚îÄ‚îÄ images/\n",
    "    ‚îî‚îÄ‚îÄ labels/\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b88ce",
   "metadata": {
    "id": "d99b88ce",
    "outputId": "81d02dbc-c46f-4457-e593-8d00db0e492d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîÄ Preparing Train/Val/Test splits...\n",
      "üìä Split Ratio: 70% Train / 15% Val / 15% Test\n",
      "======================================================================\n",
      "\n",
      "person              : Train= 70 | Val=15 | Test=15\n",
      "bicycle             : Train= 70 | Val=15 | Test=15\n",
      "car                 : Train= 70 | Val=15 | Test=15\n",
      "motorcycle          : Train= 70 | Val=15 | Test=15\n",
      "airplane            : Train= 70 | Val=15 | Test=15\n",
      "bus                 : Train= 70 | Val=15 | Test=15\n",
      "truck               : Train= 70 | Val=15 | Test=15\n",
      "traffic light       : Train= 70 | Val=15 | Test=15\n",
      "stop sign           : Train= 70 | Val=15 | Test=15\n",
      "bench               : Train= 70 | Val=15 | Test=15\n",
      "bird                : Train= 70 | Val=15 | Test=15\n",
      "cat                 : Train= 70 | Val=15 | Test=15\n",
      "dog                 : Train= 70 | Val=15 | Test=15\n",
      "horse               : Train= 70 | Val=15 | Test=15\n",
      "cow                 : Train= 70 | Val=15 | Test=15\n",
      "elephant            : Train= 70 | Val=15 | Test=15\n",
      "bottle              : Train= 70 | Val=15 | Test=15\n",
      "cup                 : Train= 70 | Val=15 | Test=15\n",
      "bowl                : Train= 70 | Val=15 | Test=15\n",
      "pizza               : Train= 70 | Val=15 | Test=15\n",
      "cake                : Train= 70 | Val=15 | Test=15\n",
      "chair               : Train= 70 | Val=15 | Test=15\n",
      "couch               : Train= 70 | Val=15 | Test=15\n",
      "bed                 : Train= 70 | Val=15 | Test=15\n",
      "potted plant        : Train= 70 | Val=15 | Test=15\n"
     ]
    }
   ],
   "source": [
    "## STEP 5: TRAIN/VAL/TEST SPLIT (70/15/15)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîÄ Preparing Train/Val/Test splits...\")\n",
    "print(\"üìä Split Ratio: 70% Train / 15% Val / 15% Test\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Initialize metadata dictionary\n",
    "metadata = {\n",
    "    'total_images': 0,\n",
    "    'classes': {},\n",
    "    'splits': {'train': 0, 'val': 0, 'test': 0}\n",
    "}\n",
    "\n",
    "# Create split dictionaries for each class\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "test_data = {}\n",
    "\n",
    "# Process each class\n",
    "for class_name in SELECTED_CLASSES.keys():\n",
    "\n",
    "    all_items = class_images.get(class_name, [])\n",
    "\n",
    "    if not all_items:\n",
    "        print(f\"‚ö†Ô∏è Warning: No images found for {class_name}\")\n",
    "        continue\n",
    "\n",
    "    # Calculate split indices\n",
    "    n = len(all_items)\n",
    "    train_split = int(0.7 * n)   # 70% for training\n",
    "    val_split = int(0.85 * n)    # 15% for validation\n",
    "    # Remaining 15% for test\n",
    "\n",
    "    # Split the data\n",
    "    train_data[class_name] = all_items[:train_split]\n",
    "    val_data[class_name] = all_items[train_split:val_split]\n",
    "    test_data[class_name] = all_items[val_split:]\n",
    "\n",
    "    # Store split info in metadata\n",
    "    metadata['classes'][class_name] = {\n",
    "        'train': len(train_data[class_name]),\n",
    "        'val': len(val_data[class_name]),\n",
    "        'test': len(test_data[class_name]),\n",
    "        'total': len(all_items)\n",
    "    }\n",
    "\n",
    "    metadata['splits']['train'] += len(train_data[class_name])\n",
    "    metadata['splits']['val'] += len(val_data[class_name])\n",
    "    metadata['splits']['test'] += len(test_data[class_name])\n",
    "    metadata['total_images'] += len(all_items)\n",
    "\n",
    "    print(f\"{class_name:20s}: Train={len(train_data[class_name]):3d} | Val={len(val_data[class_name]):2d} | Test={len(test_data[class_name]):2d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48556611",
   "metadata": {
    "id": "48556611",
    "outputId": "af7f2836-805b-4063-bda2-642c6a7a060e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üíæ STEP 6: SAVING IMAGES TO DISK\n",
      "======================================================================\n",
      "\n",
      "üìÅ PART A: Saving Classification Images...\n",
      "   Format: Cropped objects, 224x224 pixels\n",
      "\n",
      "üìÇ Processing TRAIN split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing VAL split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 31.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing TEST split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 31.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ CLASSIFICATION IMAGES SAVED!\n",
      "======================================================================\n",
      "üìä Train: 1750 images\n",
      "üìä Val:   375 images\n",
      "üìä Test:  375 images\n",
      "üìä Total: 2500 images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üíæ STEP 6: SAVING IMAGES TO DISK\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# PART A: SAVE CLASSIFICATION IMAGES\n",
    "\n",
    "\n",
    "print(\"üìÅ PART A: Saving Classification Images...\")\n",
    "print(\"   Format: Cropped objects, 224x224 pixels\\n\")\n",
    "\n",
    "classification_stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "\n",
    "# Process each split\n",
    "for split_name, split_data in [('train', train_data), ('val', val_data), ('test', test_data)]:\n",
    "\n",
    "    print(f\"üìÇ Processing {split_name.upper()} split...\")\n",
    "\n",
    "    # Process each class\n",
    "    for class_name, items in tqdm(split_data.items(), desc=f\"  {split_name}\"):\n",
    "\n",
    "        class_folder = f\"{BASE_DIR}/classification/{split_name}/{class_name}\"\n",
    "\n",
    "        # Save each image\n",
    "        for img_idx, item in enumerate(items):\n",
    "\n",
    "            img = item['image']\n",
    "            annotations = item['annotations']\n",
    "            bboxes = annotations['bbox']\n",
    "            categories = annotations['category']\n",
    "\n",
    "            class_id = SELECTED_CLASSES[class_name]\n",
    "\n",
    "            # Find bbox for this class\n",
    "            for bbox, cat_id in zip(bboxes, categories):\n",
    "                if cat_id == class_id:\n",
    "                    x, y, w, h = bbox\n",
    "\n",
    "                    try:\n",
    "                        # Crop and resize\n",
    "                        cropped_img = img.crop((x, y, x + w, y + h))\n",
    "                        cropped_img = cropped_img.resize((224, 224), Image.LANCZOS)\n",
    "\n",
    "                        # Save\n",
    "                        img_filename = f\"{class_name}_{split_name}_{img_idx:04d}.jpg\"\n",
    "                        img_path = os.path.join(class_folder, img_filename)\n",
    "                        cropped_img.save(img_path, quality=95)\n",
    "\n",
    "                        classification_stats[split_name] += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Error: {class_name} image {img_idx}: {e}\")\n",
    "\n",
    "                    break\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ CLASSIFICATION IMAGES SAVED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìä Train: {classification_stats['train']} images\")\n",
    "print(f\"üìä Val:   {classification_stats['val']} images\")\n",
    "print(f\"üìä Test:  {classification_stats['test']} images\")\n",
    "print(f\"üìä Total: {sum(classification_stats.values())} images\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35bbc9",
   "metadata": {
    "id": "df35bbc9",
    "outputId": "41f8cda0-6ded-4592-92e5-486bb6bf77a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìÅ PART B: Saving Detection Images & Annotations...\n",
      "   Format: Full images with YOLO .txt labels\n",
      "\n",
      "üìä Total detection images: 2125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving detection data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2125/2125 [00:05<00:00, 366.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ DETECTION DATASET CREATED!\n",
      "======================================================================\n",
      "üìä Images:     2125\n",
      "üìä Labels:     2125\n",
      "üìä Objects:    10986\n",
      "üìä Avg/image:  5.17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PART B: SAVE DETECTION IMAGES (YOLO FORMAT)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìÅ PART B: Saving Detection Images & Annotations...\")\n",
    "print(\"   Format: Full images with YOLO .txt labels\\n\")\n",
    "\n",
    "detection_stats = {'images': 0, 'annotations': 0, 'objects': 0}\n",
    "\n",
    "# COCO to YOLO class mapping\n",
    "coco_to_yolo = {class_id: idx for idx, class_id in enumerate(SELECTED_CLASSES.values())}\n",
    "\n",
    "# Combine train + val for detection\n",
    "all_detection_data = []\n",
    "for class_name in SELECTED_CLASSES.keys():\n",
    "    all_detection_data.extend(train_data.get(class_name, []))\n",
    "    all_detection_data.extend(val_data.get(class_name, []))\n",
    "\n",
    "print(f\"üìä Total detection images: {len(all_detection_data)}\\n\")\n",
    "\n",
    "# Save images and create YOLO labels\n",
    "for img_idx, item in enumerate(tqdm(all_detection_data, desc=\"Saving detection data\")):\n",
    "\n",
    "    img = item['image']\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    # Save full image\n",
    "    img_filename = f\"image_{img_idx:06d}.jpg\"\n",
    "    img_path = os.path.join(f\"{BASE_DIR}/detection/images\", img_filename)\n",
    "    img.save(img_path, quality=95)\n",
    "    detection_stats['images'] += 1\n",
    "\n",
    "    # Get annotations\n",
    "    annotations = item['annotations']\n",
    "    bboxes = annotations['bbox']\n",
    "    categories = annotations['category']\n",
    "\n",
    "    # Create YOLO annotation\n",
    "    label_filename = f\"image_{img_idx:06d}.txt\"\n",
    "    label_path = os.path.join(f\"{BASE_DIR}/detection/labels\", label_filename)\n",
    "\n",
    "    yolo_annotations = []\n",
    "    objects_count = 0\n",
    "\n",
    "    for bbox, cat_id in zip(bboxes, categories):\n",
    "        if cat_id in coco_to_yolo:\n",
    "            x, y, w, h = bbox\n",
    "\n",
    "            # Convert to YOLO format (normalized)\n",
    "            x_center = (x + w/2) / img_width\n",
    "            y_center = (y + h/2) / img_height\n",
    "            w_norm = w / img_width\n",
    "            h_norm = h / img_height\n",
    "\n",
    "            yolo_class_id = coco_to_yolo[cat_id]\n",
    "            yolo_line = f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\"\n",
    "            yolo_annotations.append(yolo_line)\n",
    "            objects_count += 1\n",
    "\n",
    "    # Save label file\n",
    "    if yolo_annotations:\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('\\n'.join(yolo_annotations))\n",
    "        detection_stats['annotations'] += 1\n",
    "        detection_stats['objects'] += objects_count\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ DETECTION DATASET CREATED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìä Images:     {detection_stats['images']}\")\n",
    "print(f\"üìä Labels:     {detection_stats['annotations']}\")\n",
    "print(f\"üìä Objects:    {detection_stats['objects']}\")\n",
    "print(f\"üìä Avg/image:  {detection_stats['objects']/detection_stats['images']:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9222e7a",
   "metadata": {
    "id": "f9222e7a",
    "outputId": "1b1c0426-9c1d-4aad-d29b-fca10926226d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Creating YOLO configuration file...\n",
      "\n",
      "‚úÖ Created: smartvision_dataset/detection/data.yaml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PART C: CREATE YOLO CONFIG FILE\n",
    "\n",
    "print(\"üìù Creating YOLO configuration file...\\n\")\n",
    "\n",
    "yaml_content = f\"\"\"# SmartVision Dataset - YOLOv8 Configuration\n",
    "path: {os.path.abspath(BASE_DIR)}/detection\n",
    "train: images\n",
    "val: images\n",
    "\n",
    "names:\n",
    "  0: person\n",
    "  1: bicycle\n",
    "  2: car\n",
    "  3: motorcycle\n",
    "  4: airplane\n",
    "  5: bus\n",
    "  6: truck\n",
    "  7: traffic light\n",
    "  8: stop sign\n",
    "  9: bench\n",
    "  10: bird\n",
    "  11: cat\n",
    "  12: dog\n",
    "  13: horse\n",
    "  14: cow\n",
    "  15: elephant\n",
    "  16: bottle\n",
    "  17: cup\n",
    "  18: bowl\n",
    "  19: pizza\n",
    "  20: cake\n",
    "  21: chair\n",
    "  22: couch\n",
    "  23: bed\n",
    "  24: potted plant\n",
    "\n",
    "nc: 25\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = f\"{BASE_DIR}/detection/data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"‚úÖ Created: {yaml_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2390e9",
   "metadata": {
    "id": "6a2390e9",
    "outputId": "d10d6f0a-ff54-4c95-c1fc-ac747b79c580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Saving metadata...\n",
      "\n",
      "‚úÖ Saved: smartvision_dataset/dataset_metadata.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PART D: SAVE METADATA\n",
    "\n",
    "print(\"üìä Saving metadata...\\n\")\n",
    "\n",
    "metadata['classification'] = classification_stats\n",
    "metadata['detection'] = detection_stats\n",
    "metadata['dataset_path'] = os.path.abspath(BASE_DIR)\n",
    "\n",
    "metadata_path = f\"{BASE_DIR}/dataset_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, indent=2, fp=f)\n",
    "\n",
    "print(f\"‚úÖ Saved: {metadata_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216bcbb",
   "metadata": {
    "id": "f216bcbb",
    "outputId": "fcaea36c-1e6a-40c9-cb63-132ab8f317d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéâ DATASET SETUP COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Location: /Users/subhisapple/Desktop/SmartVision_AI/smartvision_dataset\n",
      "\n",
      "üìÇ Classification Dataset:\n",
      "   ‚îú‚îÄ Train:  1750 images (70%)\n",
      "   ‚îú‚îÄ Val:    375 images (15%)\n",
      "   ‚îú‚îÄ Test:   375 images (15%)\n",
      "   ‚îî‚îÄ Total:  2500 cropped images (224x224)\n",
      "\n",
      "üìÇ Detection Dataset:\n",
      "   ‚îú‚îÄ Images: 2125 full images\n",
      "   ‚îú‚îÄ Labels: 2125 YOLO .txt files\n",
      "   ‚îî‚îÄ Objects: 10986 annotated objects\n",
      "\n",
      "======================================================================\n",
      "‚úÖ LEARNERS CAN NOW START:\n",
      "======================================================================\n",
      "Step 7:  Exploratory Data Analysis (EDA)\n",
      "Step 8:  Train Classification Models\n",
      "Step 9:  Train YOLO Detection Model\n",
      "Step 10: Build Streamlit Application\n",
      "Step 11: Deploy to Hugging Face Spaces\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéâ DATASET SETUP COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"üìÅ Location: {os.path.abspath(BASE_DIR)}\")\n",
    "print()\n",
    "print(\"üìÇ Classification Dataset:\")\n",
    "print(f\"   ‚îú‚îÄ Train:  {classification_stats['train']} images (70%)\")\n",
    "print(f\"   ‚îú‚îÄ Val:    {classification_stats['val']} images (15%)\")\n",
    "print(f\"   ‚îú‚îÄ Test:   {classification_stats['test']} images (15%)\")\n",
    "print(f\"   ‚îî‚îÄ Total:  {sum(classification_stats.values())} cropped images (224x224)\")\n",
    "print()\n",
    "print(\"üìÇ Detection Dataset:\")\n",
    "print(f\"   ‚îú‚îÄ Images: {detection_stats['images']} full images\")\n",
    "print(f\"   ‚îú‚îÄ Labels: {detection_stats['annotations']} YOLO .txt files\")\n",
    "print(f\"   ‚îî‚îÄ Objects: {detection_stats['objects']} annotated objects\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ LEARNERS CAN NOW START:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Step 7:  Exploratory Data Analysis (EDA)\")\n",
    "print(\"Step 8:  Train Classification Models\")\n",
    "print(\"Step 9:  Train YOLO Detection Model\")\n",
    "print(\"Step 10: Build Streamlit Application\")\n",
    "print(\"Step 11: Deploy to Hugging Face Spaces\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b4836",
   "metadata": {
    "id": "980b4836"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1KsjW74DSd34IGrqTIqah_jpm_Oyk43Kp",
     "timestamp": 1764140941117
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
