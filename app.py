import streamlit as st
import torch
import torch.nn as nn
from ultralytics import YOLO
from torchvision import models, transforms
from PIL import Image
import numpy as np
import cv2

# ---------------- CLASS LABELS ----------------
CLASS_NAMES = [
'Chair','bottle','Cat','Cup','Bench','Horse','Person','bed','Truck','Airplane',
'Cycle','Bird','bike','bus','potted plant','Pizza','Stop Signal','Bowl',
'Traffic Signal','couch','elephant','Cake','dog','cow','Car'
]
NUM_CLASSES = len(CLASS_NAMES)

# ---------------- PAGE CONFIG ----------------
st.set_page_config(page_title="Smart Vision AI", page_icon="ü§ñ", layout="wide")

# ---------------- SESSION STATE ----------------
if "page" not in st.session_state:
    st.session_state["page"] = "üè† Home"

# ---------------- LOAD MODELS ----------------
@st.cache_resource
def load_detection_model():
    return YOLO("SmartVision_v3.pt")

@st.cache_resource
def load_classification_model():
    model = models.mobilenet_v2(pretrained=True)
    for param in model.features.parameters():
        param.requires_grad = False
    model.classifier = nn.Sequential(
        nn.Dropout(0.3),
        nn.Linear(model.classifier[1].in_features, 1024),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(1024, NUM_CLASSES)
    )
    state_dict = torch.load("MobileNET_best.pth", map_location="cpu")
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    return model

det_model = load_detection_model()
cls_model = load_classification_model()
transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])


# ---------------- GLOBAL MODERN CSS ----------------
st.markdown("""
<style>
.section-title {
    font-size: 52px; font-weight: 900; text-align: center;
    color: #004aad;           
    margin-bottom: 5px;
}
.sub-text {
    text-align: center; font-size: 21px; color: #444; margin-bottom: 30px;
}
.card-box {
    background: white; padding: 22px; border-radius: 16px;
    box-shadow: 0px 3px 14px rgba(0,0,0,0.17);
    margin-top: 10px; margin-bottom: 18px;
}
.result-label {
    font-size: 32px; font-weight: 900; text-align:center; color: #004aad;
}
.confidence-label {
    font-size: 20px; text-align:center; margin-top: 3px; color:#404040;
}
</style>
""", unsafe_allow_html=True)


# ---------------- SIDEBAR ----------------
page = st.sidebar.radio(
    "Navigation",
    ["üè† Home", "üß† Classification", "üéØ Object Detection"],
    index=["üè† Home", "üß† Classification", "üéØ Object Detection"].index(st.session_state["page"])
)
st.session_state["page"] = page




# üè† HOME PAGE

if page == "üè† Home":

    st.markdown("<div class='section-title'>Smart Vision AI</div>", unsafe_allow_html=True)
    st.markdown("<div class='sub-text'>Advanced Deep Learning for Object Detection & Image Classification</div>", unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("<div class='card-box'><img src='https://cdn-icons-png.flaticon.com/512/2103/2103658.png' width='80'><h4>YOLO Detection</h4><p>Detect multiple objects instantly</p></div>", unsafe_allow_html=True)
    with col2:
        st.markdown("<div class='card-box'><img src='https://cdn-icons-png.flaticon.com/512/4305/4305434.png' width='80'><h4>MobileNet Classification</h4><p>Predict object class with high accuracy</p></div>", unsafe_allow_html=True)
    with col3:
        st.markdown("<div class='card-box'><img src='https://cdn-icons-png.flaticon.com/512/3602/3602145.png' width='80'><h4>Upload / Webcam</h4><p>Multiple input modes supported</p></div>", unsafe_allow_html=True)

    colA, colB = st.columns(2)
    with colA:
        if st.button("üöÄ Start Object Detection"):
            st.session_state["page"] = "üéØ Object Detection"
            st.rerun()
    with colB:
        if st.button("üß† Start Classification"):
            st.session_state["page"] = "üß† Classification"
            st.rerun()




# üß† CLASSIFICATION 

elif page == "üß† Classification":

    st.markdown("<div class='section-title'>üß† Image Classification</div>", unsafe_allow_html=True)
    st.markdown("<div class='sub-text'>Upload or capture an image to predict the object class</div>", unsafe_allow_html=True)

    input_type = st.radio("Choose Input", ["Upload Image", "Webcam"], horizontal=True)
    img = None

    if input_type == "Upload Image":
        file = st.file_uploader("Upload Image", type=["jpg","jpeg","png"])
        if file:
            img = Image.open(file).convert("RGB")
    else:
        cam = st.camera_input("Capture Image")
        if cam:
            img = Image.open(cam).convert("RGB")

    if img:
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("<div class='card-box'><b>üìå Input Image</b></div>", unsafe_allow_html=True)
            st.image(img, width=420) 

      
        tensor = trasnform(img).unsqueeze(0)  

        with torch.no_grad(): logits = cls_model(tensor)
        probs = torch.softmax(logits, dim=1)[0]
        idx = torch.argmax(probs).item()

        with col2:
            st.markdown("<div class='card-box'><b>üéØ Result</b></div>", unsafe_allow_html=True)
            st.markdown(f"<div class='result-label'>{CLASS_NAMES[idx]}</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='confidence-label'>Confidence: {probs[idx]:.2f}</div>", unsafe_allow_html=True)


# üéØ OBJECT DETECTION 

elif page == "üéØ Object Detection":

    st.markdown("<div class='section-title'>üéØ Object Detection</div>", unsafe_allow_html=True)
    st.markdown("<div class='sub-text'>Upload or capture an image for YOLO detection</div>", unsafe_allow_html=True)

    input_type = st.radio("Choose Input", ["Upload Image", "Webcam"], horizontal=True)
    img_cv = None

    if input_type == "Upload Image":
        file = st.file_uploader("Upload Image", type=["jpg","jpeg","png"])
        if file:
            data = np.frombuffer(file.read(), np.uint8)
            img_cv = cv2.imdecode(data, cv2.IMREAD_COLOR)
    else:
        snap = st.camera_input("Capture Image")
        if snap:
            pil = Image.open(snap)
            img_cv = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)

    if img_cv is not None:
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("<div class='card-box'><b>üìå Input Image</b></div>", unsafe_allow_html=True)
            st.image(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB), width=420)

        results = det_model(img_cv)
        detected_img = results[0].plot()

        with col2:
            st.markdown("<div class='card-box'><b>üéØ Detection Result</b></div>", unsafe_allow_html=True)
            st.image(cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB), width=420)
